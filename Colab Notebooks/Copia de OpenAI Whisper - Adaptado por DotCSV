{"cells":[{"cell_type":"markdown","metadata":{"id":"v5hvo8QWN-a9"},"source":["#üó£Ô∏è **Whisper** - *Notebook creado por [DotCSV](https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg)*"]},{"cell_type":"markdown","source":["üö® Ten activada la **Aceleraci√≥n por hardware** con GPU en `\"Entorno de ejecuci√≥n\" > \"Cambiar tipo de entorno de ejecuci√≥n\"`"],"metadata":{"id":"f-BcD0b8hwdA"}},{"cell_type":"code","source":["#@title ‚öôÔ∏è Ejecutar esta celda para instalar las librer√≠a.\n","\"\"\"\n","To write this piece of code I took inspiration/code from a lot of places.\n","It was late night, so I'm not sure how much I created or just copied o.O\n","Here are some of the possible references:\n","https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n","https://stackoverflow.com/a/18650249\n","https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n","https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n","https://stackoverflow.com/a/49019356\n","\"\"\"\n","\n","!pip install git+https://github.com/openai/whisper.git\n","!pip install jiwer\n","\n","from IPython.display import HTML, Audio\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","from scipy.io.wavfile import read as wav_read\n","import io\n","import ffmpeg\n","\n","AUDIO_HTML = \"\"\"\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n","\"\"\"\n","\n","def get_audio():\n","  display(HTML(AUDIO_HTML))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","  \n","  process = (ffmpeg\n","    .input('pipe:0')\n","    .output('pipe:1', format='wav')\n","    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n","  )\n","  output, err = process.communicate(input=binary)\n","  \n","  riff_chunk_size = len(output) - 8\n","  # Break up the chunk size into four bytes, held in b.\n","  q = riff_chunk_size\n","  b = []\n","  for i in range(4):\n","      q, r = divmod(q, 256)\n","      b.append(r)\n","\n","  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n","  riff = output[:4] + bytes(b) + output[8:]\n","\n","  sr, audio = wav_read(io.BytesIO(riff))\n","\n","  return audio, sr"],"metadata":{"cellView":"form","id":"SJl7HJOeo0-P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676477438352,"user_tz":180,"elapsed":23233,"user":{"displayName":"Samuel Kanneman","userId":"15232566557853451910"}},"outputId":"6b0a312a-b592-4cfb-90ad-a3825a2685b0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-0d9bimck\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-0d9bimck\n","  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n","Collecting transformers>=4.19.0\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpeg-python==0.2.0\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179424 sha256=96238ea40cd348505477146271ac69329a41501ed4294235ed058a2dc742c1ce\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9li6t934/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n","Successfully built openai-whisper\n","Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n","Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.0 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jiwer\n","  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n","Collecting levenshtein==0.20.2\n","  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n","  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n","Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.7\n"]}]},{"cell_type":"markdown","metadata":{"id":"-9_I0W3tqTjr"},"source":["## üéôÔ∏è **Grabar y transcribir** [Elige la tarea]"]},{"cell_type":"code","source":["Tarea = \"Transcript to Language\" #@param [\"Transcript to Language\", \"Translate to English\"]\n","import numpy as np\n","import whisper\n","from scipy.io.wavfile import write\n","from IPython.display import clear_output\n","\n","task = \"translate\" if Tarea == \"Translate to English\" else \"transcribe\" \n","\n","audio, sr = get_audio()\n","write('record.wav', sr, audio)\n","\n","!whisper \"record.wav\" --task {task} --model medium --verbose False\n","\n","clear_output()\n","if task == \"translate\":\n","  print(\"-- TRADUCCI√ìN A INGL√âS --\\n\")\n","else:\n","  print(\"-- TRANSCRIPCI√ìN A ESPA√ëOL --\\n\")\n","  \n","print(open('record.wav.txt').read())"],"metadata":{"id":"opNkn_Lgpat4","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üëâ  S√≥lo **transcribir** audio al idioma original. (X ‚ñ∫ X)"],"metadata":{"id":"XXZooJ-Wy9EL"}},{"cell_type":"code","source":["!whisper \"/content/audio.mp3\" --task transcribe --model medium --verbose False --output_dir audio_transcription"],"metadata":{"id":"Aejy9Haxy81U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676479687491,"user_tz":180,"elapsed":1899497,"user":{"displayName":"Samuel Kanneman","userId":"15232566557853451910"}},"outputId":"02b33a5a-63bf-495d-8ba3-d90fa8d7f1a5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-15 16:16:30.388953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-15 16:16:31.245878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-15 16:16:31.245984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-15 16:16:31.246003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:06<00:00, 244MiB/s]\n","Detected language: Spanish\n","100% 764067/764067 [30:26<00:00, 418.28frames/s]\n"]}]},{"cell_type":"markdown","source":["## üëâ  S√≥lo **traducir** audio del idioma original al ingl√©s. (X ‚ñ∫ English)"],"metadata":{"id":"wOdSeKWnzJSV"}},{"cell_type":"code","source":["!whisper \"/content/audio.mp3\" --task translate --model medium"],"metadata":{"id":"UlVRSbPC7IRJ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1CvvYPAFemIZdSOt9fhN541esSlZR7Ic6","timestamp":1676476345166},{"file_id":"1lXtPVNqMy-lg1QrGOG9qZ96rOXNMnNrh","timestamp":1668360149938},{"file_id":"https://github.com/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb","timestamp":1667820298272}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}